#!/usr/bin/env python3
"""
Starke training script functions. Orchestration logic is in an experiment classes.

Supports starke repo validation, python script parameter adjustements, and subprocess
training script calls with real-time output parsing.

Function-based Design Rationale:
- Functions provide clear, testable building blocks for training operations
- Easy to restructure and compose functions into potential PAE-only, GNN-only experiments
- Stateless functions are simpler to debug and reason about
"""
import logging
import re
import shutil
from pathlib import Path
from typing import Dict, Union

from data.motion_preprocessing import (
    MotionProcessor,
    count_lines,
    parse_input_output_features,
)
from .script_subprocess import run_script_subprocess
from .script_editing import read_script_variables, write_script_variables, reset_script
from config.model_configs import StarkeModelConfig
from experiment_tracker import ExperimentTracker

logger = logging.getLogger(__name__)

# PAE velocity features: 26 joints * 3 dimensions = 78 features
PAE_VELOCITY_FEATURE_COUNT = 78


def pytorch_path(path_to_ai4anim: Path) -> Path:
    """
    Get the PyTorch directory path.

    :param path_to_ai4anim: Path to AI4Animation framework
    :return: Path to PyTorch directory
    """
    return path_to_ai4anim / "AI4Animation" / "SIGGRAPH_2022" / "PyTorch"


def pae_path(path_to_ai4anim: Path) -> Path:
    """
    Get the PAE directory path.

    :param path_to_ai4anim: Path to AI4Animation framework
    :return: Path to PAE directory
    """
    return pytorch_path(path_to_ai4anim) / "PAE"


def gnn_path(path_to_ai4anim: Path) -> Path:
    """
    Get the GNN directory path.

    :param path_to_ai4anim: Path to AI4Animation framework
    :return: Path to GNN directory
    """
    return pytorch_path(path_to_ai4anim) / "GNN"


def init_model(config: StarkeModelConfig) -> None:
    """
    Initialize model by setting hyperparameters and parameters inferred from input data.

    :param config: Starke model configuration
    """
    # PAE data loading requires input feature metadata
    _init_pae_data_shape(config.dataset_path, config.path_to_ai4anim)

    # Initialize PAE network with epochs and learning rate
    pae_updates = {
        "epochs": config.pae_epochs,
        "learning_rate": config.pae_learning_rate,
    }
    _init_pae_network_script(config.path_to_ai4anim, pae_updates)

    # Initialize GNN network with epochs, learning rate, dropout, and input feature-based parameters
    gnn_updates = _init_gnn_feature_count(config.dataset_path)
    gnn_updates["epochs"] = config.gnn_epochs
    gnn_updates["learning_rate"] = config.gnn_learning_rate
    gnn_updates["dropout"] = config.gnn_dropout
    _init_gnn_network_script(config.path_to_ai4anim, gnn_updates)


def _init_pae_data_shape(dataset_path: Path, path_to_ai4anim: Path) -> None:
    """
    Initialize PAE data shape by reading sequence count and writing to DataShape.txt.

    :param dataset_path: Path to the dataset directory containing sequences_velocity.txt
    :param path_to_ai4anim: Path to AI4Animation framework
    :raises RuntimeError: If sequence file not found or writing fails
    """
    sequences_file = dataset_path / "sequences_velocity.txt"

    if not sequences_file.exists():
        suggestion = (
            f"Ensure the dataset at {dataset_path} contains 'sequences_velocity.txt'. "
            "This file should be generated by the velocity preprocessing step."
        )
        logger.error(f"Sequences file not found: {sequences_file}. {suggestion}")
        raise RuntimeError(f"Sequences file not found: {sequences_file}. {suggestion}")

    # Count lines in sequences_velocity.txt
    velocity_samples = count_lines(str(sequences_file))
    logger.info(f"Found {velocity_samples} velocity samples in sequences file")

    # Write to PAE DataShape.txt
    pae_data_shapes_path = pae_path(path_to_ai4anim) / "Dataset" / "DataShape.txt"

    # Create backup if original exists
    if pae_data_shapes_path.exists():
        backup_path = pae_data_shapes_path.with_suffix(
            pae_data_shapes_path.suffix + ".animhost_backup"
        )
        try:
            backup_content = pae_data_shapes_path.read_text(encoding="utf-8")
            backup_path.write_text(backup_content, encoding="utf-8")
            logger.info(f"Created backup: {backup_path}")
        except Exception as e:
            logger.error(f"Failed to create backup: {e}")
            raise RuntimeError(f"Failed to create backup: {e}")

    # Write new DataShape.txt content
    data_shapes_content = f"{velocity_samples}\n{PAE_VELOCITY_FEATURE_COUNT}"

    try:
        pae_data_shapes_path.write_text(data_shapes_content, encoding="utf-8")
        logger.info(
            f"Successfully wrote PAE DataShape.txt: {velocity_samples} samples, {PAE_VELOCITY_FEATURE_COUNT} features"
        )
    except Exception as e:
        logger.error(f"Failed to write DataShape.txt: {e}")
        raise RuntimeError(f"Failed to write DataShape.txt: {e}")


def _init_pae_network_script(
    path_to_ai4anim: Path, updates: Dict[str, Union[int, float]]
) -> None:
    """
    Initialize PAE Network.py with configuration parameters.

    :param path_to_ai4anim: Path to AI4Animation framework
    :param updates: Dictionary of parameter updates (epochs, learning_rate)
    :raises RuntimeError: If script editing fails
    """
    pae_network_path = pae_path(path_to_ai4anim) / "Network.py"

    # Read current values for logging
    current_values = read_script_variables(pae_network_path, list(updates.keys()))

    # Apply all updates
    error = write_script_variables(pae_network_path, updates)
    if error:
        logger.error(f"Failed to update PAE Network.py: {error}")
        raise RuntimeError(f"Failed to update PAE Network.py: {error}")

    # Log all changes
    logger.info("Successfully updated PAE Network.py with:")
    for key, new_value in updates.items():
        old_value = current_values.get(key)
        logger.info(f"  {key}: {old_value} -> {new_value}")


def _init_gnn_network_script(
    path_to_ai4anim: Path, updates: Dict[str, Union[str, int, float]]
) -> None:
    """
    Initialize GNN Network.py with all parameter updates in a single operation.

    :param path_to_ai4anim: Path to AI4Animation framework
    :param updates: Dictionary of parameter updates (epochs, learning_rate, dropout, gating_indices, main_indices)
    :raises RuntimeError: If script editing fails
    """
    gnn_network_path = gnn_path(path_to_ai4anim) / "Network.py"

    # Read current values for logging
    current_values = read_script_variables(gnn_network_path, list(updates.keys()))

    # Apply all updates in a single operation
    error = write_script_variables(gnn_network_path, updates)
    if error:
        logger.error(f"Failed to update GNN Network.py: {error}")
        raise RuntimeError(f"Failed to update GNN Network.py: {error}")

    # Log all changes
    logger.info(f"Successfully updated GNN Network.py with:")
    for key, new_value in updates.items():
        old_value = current_values.get(key)
        logger.info(f"  {key}: {old_value} -> {new_value}")


def _init_gnn_feature_count(dataset_path: Path) -> Dict[str, str]:
    """
    Read dataset metadata and return GNN Network.py parameter updates.

    :param dataset_path: Path to the dataset directory containing metadata.txt
    :return: Dictionary of parameter updates for GNN Network.py
    :raises RuntimeError: If parsing metadata fails
    """
    metadata_file = dataset_path / "metadata.txt"

    if not metadata_file.exists():
        suggestion = (
            f"Ensure the dataset at {dataset_path} contains 'metadata.txt'. "
            "This file should contain input/output feature counts generated during preprocessing."
        )
        logger.error(f"Metadata file not found: {metadata_file}. {suggestion}")
        raise RuntimeError(f"Metadata file not found: {metadata_file}. {suggestion}")

    # Parse input/output features from metadata.txt
    input_feature_count, output_feature_count = parse_input_output_features(
        str(metadata_file)
    )
    logger.info(
        f"Parsed features - Input: {input_feature_count}, Output: {output_feature_count}"
    )

    # Generate gating_indices and main_indices tensors
    gating_indices_expr = (
        f"torch.tensor([({input_feature_count} + i) for i in range(130)])"
    )
    main_indices_expr = f"torch.tensor([(0 + i) for i in range({input_feature_count})])"

    logger.info(f"Generated GNN parameter updates:")
    logger.info(f"  gating_indices = {gating_indices_expr}")
    logger.info(f"  main_indices = {main_indices_expr}")

    return {"gating_indices": gating_indices_expr, "main_indices": main_indices_expr}


def reset_model(path_to_ai4anim: Path) -> None:
    """
    Reset PAE and GNN Network.py files and PAE DataShape.txt from their backup copies.

    :param path_to_ai4anim: Path to AI4Animation framework
    :raises RuntimeError: If reset fails
    """
    # Reset PAE Network.py
    pae_network_path = pae_path(path_to_ai4anim) / "Network.py"
    error = reset_script(pae_network_path)
    if error:
        logger.error(f"Failed to reset PAE Network.py: {error}")
        raise RuntimeError(f"Failed to reset PAE Network.py: {error}")
    logger.info("Reset PAE Network.py from backup")

    # Reset PAE DataShape.txt
    pae_data_shapes_path = pae_path(path_to_ai4anim) / "Dataset" / "DataShape.txt"
    backup_path = pae_data_shapes_path.with_suffix(
        pae_data_shapes_path.suffix + ".animhost_backup"
    )

    if backup_path.exists():
        try:
            backup_content = backup_path.read_text(encoding="utf-8")
            pae_data_shapes_path.write_text(backup_content, encoding="utf-8")
            backup_path.unlink()
            logger.info("Reset PAE DataShape.txt from backup")
        except Exception as e:
            logger.error(f"Failed to reset PAE DataShape.txt: {e}")
            raise RuntimeError(f"Failed to reset PAE DataShape.txt: {e}")
    else:
        logger.warning("No backup found for PAE DataShape.txt")

    # Reset GNN Network.py
    gnn_network_path = gnn_path(path_to_ai4anim) / "Network.py"
    error = reset_script(gnn_network_path)
    if error:
        logger.error(f"Failed to reset GNN Network.py: {error}")
        raise RuntimeError(f"Failed to reset GNN Network.py: {error}")
    logger.info("Reset GNN Network.py from backup")


def validate_ai4animation_structure(path_to_ai4anim: Path) -> bool:
    """
    Validate AI4Animation framework structure for both PAE and GNN training phases.

    :param path_to_ai4anim: Path to AI4Animation framework
    :returns: True if structure is valid, False otherwise
    """
    # Validate PyTorch directory exists
    pytorch_dir = pytorch_path(path_to_ai4anim)
    if not pytorch_dir.exists() or not pytorch_dir.is_dir():
        logger.error(
            f"AI4Animation PyTorch directory not found at {pytorch_dir}. "
            "Ensure AI4Animation is properly cloned and the path_to_ai4anim "
            "configuration points to the correct directory."
        )
        return False

    # Validate PAE directory
    pae_dir = pae_path(path_to_ai4anim)
    if not pae_dir.exists() or not pae_dir.is_dir():
        logger.error(
            f"AI4Animation PAE directory not found at {pae_dir}. "
            "Ensure AI4Animation is properly cloned and the path_to_ai4anim "
            "configuration points to the correct directory."
        )
        return False

    pae_network_script = pae_dir / "Network.py"
    if not pae_network_script.exists() or not pae_network_script.is_file():
        logger.error(
            f"AI4Animation PAE Network.py script not found at {pae_network_script}"
        )
        return False

    pae_dataset_path = pae_dir / "Dataset"
    if not pae_dataset_path.exists() or not pae_dataset_path.is_dir():
        logger.error(
            f"AI4Animation PAE Dataset directory not found at {pae_dataset_path}"
        )
        return False

    # Validate GNN directory
    gnn_dir = gnn_path(path_to_ai4anim)
    if not gnn_dir.exists() or not gnn_dir.is_dir():
        logger.error(
            f"AI4Animation GNN directory not found at {gnn_dir}. "
            "Ensure AI4Animation is properly cloned and the path_to_ai4anim "
            "configuration points to the correct directory."
        )
        return False

    gnn_network_script = gnn_dir / "Network.py"
    if not gnn_network_script.exists() or not gnn_network_script.is_file():
        logger.error(
            f"AI4Animation GNN Network.py script not found at {gnn_network_script}"
        )
        return False

    gnn_data_path = gnn_dir / "Data"
    if not gnn_data_path.exists() or not gnn_data_path.is_dir():
        logger.error(f"AI4Animation GNN Data directory not found at {gnn_data_path}")
        return False

    return True


def run_pae_training(
    config: StarkeModelConfig, tracker: ExperimentTracker
) -> bool:
    """
    PAE (Phase Autoencoder) training subprocess with real-time parsing.

    Copies training data to PAE directory and launches the PAE Network.py subprocess
    with real-time output parsing for progress updates.

    :param config: StarkeModelConfig containing all training parameters
    :param tracker: ExperimentTracker instance for logging
    :return: True on success, False on failure
    """
    tracker.log_ui_status("Starting training 1/2 ...", "Starting PAE training phase...")

    # Validate input files exist
    p_velocity_file = config.dataset_path / "p_velocity.bin"
    sequences_file = config.dataset_path / "sequences_velocity.txt"

    if not p_velocity_file.exists() or not p_velocity_file.is_file():
        suggestion = (
            "Run velocity preprocessing to generate this file, or check that the "
            "dataset path is correct."
        )
        logger.error(
            f"Required PAE input file not found: {p_velocity_file}. {suggestion}"
        )
        raise RuntimeError(
            f"Required PAE input file missing: p_velocity.bin. {suggestion}"
        )

    if not sequences_file.exists() or not sequences_file.is_file():
        suggestion = (
            "Run velocity preprocessing to generate this file, or check that the "
            "dataset path is correct."
        )
        logger.error(
            f"Required PAE input file not found: {sequences_file}. {suggestion}"
        )
        raise RuntimeError(
            f"Required PAE input file missing: sequences_velocity.txt. {suggestion}"
        )

    # PAE preprocessing - copy training data to PAE folder
    pae_dir = pae_path(config.path_to_ai4anim)
    pae_dataset_path = pae_dir / "Dataset"

    # Copy files: p_velocity.bin -> Data.bin, sequences_velocity.txt -> Sequences.txt
    shutil.copyfile(p_velocity_file, pae_dataset_path / "Data.bin")
    shutil.copyfile(sequences_file, pae_dataset_path / "Sequences.txt")

    # Launch PAE Network.py subprocess
    # Use MPLBACKEND=Agg to suppress matplotlib windows because they don't show anything
    return_code, stderr = run_script_subprocess(
        script_name="Network.py",
        working_dir=pae_dir,
        model_name="Encoder",
        line_parser=lambda line, model_name: parse_training_output(
            line, model_name, tracker
        ),
        env_overrides={"MPLBACKEND": "Agg"},
    )

    if return_code != 0:
        error_msg = f"PAE training subprocess failed with return code {return_code}"
        if stderr:
            error_msg += f"\nStderr output:\n{stderr}"
        tracker.log_exception("PAE Training Failed", RuntimeError(error_msg))
        return False

    # Validate expected output file exists
    expected_params_file = pae_dir / "Training" / f"Parameters_{config.pae_epochs}.txt"
    if not expected_params_file.exists():
        error_msg = f"PAE training completed but expected output file not found: {expected_params_file}"
        if stderr:
            error_msg += f"\nStderr output:\n{stderr}"
        tracker.log_exception("PAE Training Validation Failed", RuntimeError(error_msg))
        return False

    logger.info(f"PAE training completed successfully. Output validated: {expected_params_file}")
    return True


def run_gnn_training(config: StarkeModelConfig, tracker: ExperimentTracker) -> bool:
    """
    GNN (Graph Neural Network) training subprocess with real-time parsing.

    Preprocesses motion data using MotionProcessor and launches the GNN Network.py
    subprocess with real-time output parsing for progress updates.

    :param config: StarkeModelConfig containing all training parameters
    :param tracker: ExperimentTracker instance for logging
    :return: True on success, False on failure
    """
    tracker.log_ui_status("Starting training 2/2 ...", "Starting GNN training phase...")

    # Initialize motion processor
    mp = MotionProcessor(
        str(config.dataset_path), str(pytorch_path(config.path_to_ai4anim)), config.pae_epochs
    )

    # GNN preprocessing - prepare training data for generator
    mp.input_preprocessing()
    mp.output_preprocessing()
    processed_data_path = config.dataset_path / "processed"
    mp.export_data(folder_path=str(processed_data_path) + "/")

    # Copy all files from processed folder to GNN folder
    gnn_dir = gnn_path(config.path_to_ai4anim)
    for file_path in processed_data_path.iterdir():
        if file_path.is_file():  # Only copy files, not directories
            shutil.copyfile(file_path, gnn_dir / "Data" / file_path.name)

    # Launch GNN Network.py subprocess
    return_code, stderr = run_script_subprocess(
        script_name="Network.py",
        working_dir=gnn_dir,
        model_name="Controller",
        line_parser=lambda line, model_name: parse_training_output(
            line, model_name, tracker
        ),
    )

    if return_code != 0:
        error_msg = f"GNN training subprocess failed with return code {return_code}"
        if stderr:
            error_msg += f"\nStderr output:\n{stderr}"
        tracker.log_exception("GNN Training Failed", RuntimeError(error_msg))
        return False

    logger.info("GNN training completed successfully")
    return True


def move_pae_artifacts(path_to_ai4anim: Path, dest_dir: Path) -> bool:
    """
    Move PAE training artifacts to destination directory.

    Moves files from AI4Animation/SIGGRAPH_2022/PyTorch/PAE/Training/ to dest_dir/PAE/Training/
    Overwrites existing files with the same name.

    :param path_to_ai4anim: Path to AI4Animation framework
    :param dest_dir: Destination directory for artifacts
    :return: True on success, False on failure
    """
    try:
        pae_source = pae_path(path_to_ai4anim) / "Training"
        pae_dest = dest_dir / "PAE" / "Training"

        if not pae_source.exists():
            logger.warning(f"PAE training directory not found: {pae_source}")
            return False

        if not pae_source.is_dir():
            logger.error(f"PAE training path is not a directory: {pae_source}")
            return False

        # Create destination directory
        pae_dest.mkdir(parents=True, exist_ok=True)

        # Move all files from source to destination
        moved_count = 0
        for item in pae_source.iterdir():
            dest_item = pae_dest / item.name
            shutil.move(str(item), str(dest_item))
            moved_count += 1

        logger.info(f"Moved {moved_count} PAE training artifacts from {pae_source} to {pae_dest}")
        return True

    except Exception as e:
        logger.error(f"Failed to move PAE artifacts: {e}", exc_info=True)
        return False


def move_gnn_artifacts(path_to_ai4anim: Path, dest_dir: Path) -> bool:
    """
    Move GNN training artifacts to destination directory.

    Moves files from AI4Animation/SIGGRAPH_2022/PyTorch/GNN/Training/ to dest_dir/GNN/Training/
    Overwrites existing files with the same name.

    :param path_to_ai4anim: Path to AI4Animation framework
    :param dest_dir: Destination directory for artifacts
    :return: True on success, False on failure
    """
    try:
        gnn_source = gnn_path(path_to_ai4anim) / "Training"
        gnn_dest = dest_dir / "GNN" / "Training"

        if not gnn_source.exists():
            logger.warning(f"GNN training directory not found: {gnn_source}")
            return False

        if not gnn_source.is_dir():
            logger.error(f"GNN training path is not a directory: {gnn_source}")
            return False

        # Create destination directory
        gnn_dest.mkdir(parents=True, exist_ok=True)

        # Move all files from source to destination (skip placeholder.txt)
        moved_count = 0
        for item in gnn_source.iterdir():
            if item.name == "placeholder.txt":
                continue
            dest_item = gnn_dest / item.name
            shutil.move(str(item), str(dest_item))
            moved_count += 1

        logger.info(f"Moved {moved_count} GNN training artifacts from {gnn_source} to {gnn_dest}")
        return True

    except Exception as e:
        logger.error(f"Failed to move GNN artifacts: {e}", exc_info=True)
        return False


def parse_training_output(
    line: str, model_name: str, tracker: ExperimentTracker
) -> None:
    """
    Parse Network.py output (both PAE and GNN) and emit JSON to stdout.

    Handles consistent output format:

    - "Epoch 1 0.32931875690483264" (epoch + loss)
    - "Progress 23.42 %" (progress percentage)
    - All other lines go getted logged as debug info

    :param line: Output line from Network.py
    :param model_name: "PAE" or "GNN" for prefixing messages
    :param tracker: ExperimentTracker instance for logging
    """
    # Pattern 1: "Epoch 1 0.32931875690483264"
    epoch_pattern = re.compile(r"^Epoch\s+(\d+)\s+([\d.]+)$")
    match = epoch_pattern.search(line)
    if match:
        epoch = int(match.group(1))
        loss = float(match.group(2))
        tracker.log_epoch(
            status=f"{model_name} training",
            metrics={"epoch": epoch, "train_loss": loss},
            text=f"{model_name} epoch {epoch} completed",
        )
        return None

    # Pattern 2: "Progress 23.42 %" (configurable progress updates)
    progress_pattern = re.compile(r"^Progress\s+([\d.]+)\s*%+$")
    match = progress_pattern.search(line)
    if match:
        progress = float(match.group(1))
        tracker.log_percentage_progress(
            f"{model_name} training", progress, f"{model_name} Progress: {progress}%"
        )
        return None

    logger.debug(f"{model_name} output: {line.strip()}")
