\doxysection{Ort\+::Float16\+\_\+t Struct Reference}
\hypertarget{struct_ort_1_1_float16__t}{}\label{struct_ort_1_1_float16__t}\index{Ort::Float16\_t@{Ort::Float16\_t}}


IEEE 754 half-\/precision floating point data type.  




{\ttfamily \#include $<$onnxruntime\+\_\+cxx\+\_\+api.\+h$>$}

\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{struct_ort_1_1_float16__t_a1c4bc779a26f3b76f7603ade55f8b406}\label{struct_ort_1_1_float16__t_a1c4bc779a26f3b76f7603ade55f8b406} 
constexpr {\bfseries Float16\+\_\+t} (uint16\+\_\+t v) noexcept
\item 
\Hypertarget{struct_ort_1_1_float16__t_a8af796b50ea5871e362c4b7920d0818f}\label{struct_ort_1_1_float16__t_a8af796b50ea5871e362c4b7920d0818f} 
constexpr {\bfseries operator uint16\+\_\+t} () const noexcept
\item 
\Hypertarget{struct_ort_1_1_float16__t_a7c3e6b3763cd9ade3aeb4ff9a3fa756b}\label{struct_ort_1_1_float16__t_a7c3e6b3763cd9ade3aeb4ff9a3fa756b} 
constexpr bool {\bfseries operator==} (const \mbox{\hyperlink{struct_ort_1_1_float16__t}{Float16\+\_\+t}} \&rhs) const noexcept
\item 
\Hypertarget{struct_ort_1_1_float16__t_a075d0f6f5e3d01ee576e195fc831c077}\label{struct_ort_1_1_float16__t_a075d0f6f5e3d01ee576e195fc831c077} 
constexpr bool {\bfseries operator!=} (const \mbox{\hyperlink{struct_ort_1_1_float16__t}{Float16\+\_\+t}} \&rhs) const noexcept
\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{struct_ort_1_1_float16__t_a40e94744f6857e04292cb5af42023709}\label{struct_ort_1_1_float16__t_a40e94744f6857e04292cb5af42023709} 
uint16\+\_\+t {\bfseries value}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
IEEE 754 half-\/precision floating point data type. 

It is necessary for type dispatching to make use of C++ API The type is implicitly convertible to/from uint16\+\_\+t. The size of the structure should align with uint16\+\_\+t and one can freely cast uint16\+\_\+t buffers to/from \doxylink{struct_ort_1_1_float16__t}{Ort\+::\+Float16\+\_\+t} to feed and retrieve data.

Generally, you can feed any of your types as float16/blfoat16 data to create a tensor on top of it, providing it can form a continuous buffer with 16-\/bit elements with no padding. And you can also feed a array of uint16\+\_\+t elements directly. For example,


\begin{DoxyCode}{0}
\DoxyCodeLine{uint16\_t\ values[]\ =\ \{\ 15360,\ 16384,\ 16896,\ 17408,\ 17664\};}
\DoxyCodeLine{constexpr\ size\_t\ values\_length\ =\ sizeof(values)\ /\ sizeof(values[0]);}
\DoxyCodeLine{std::vector<int64\_t>\ dims\ =\ \{values\_length\};\ \ //\ one\ dimensional\ example}
\DoxyCodeLine{Ort::MemoryInfo\ info("{}Cpu"{},\ OrtDeviceAllocator,\ 0,\ OrtMemTypeDefault);}
\DoxyCodeLine{//\ Note\ we\ are\ passing\ bytes\ count\ in\ this\ api,\ not\ number\ of\ elements\ -\/>\ sizeof(values)}
\DoxyCodeLine{auto\ float16\_tensor\ =\ Ort::Value::CreateTensor(info,\ values,\ sizeof(values),}
\DoxyCodeLine{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ dims.data(),\ dims.size(),\ ONNX\_TENSOR\_ELEMENT\_DATA\_TYPE\_FLOAT16);}

\end{DoxyCode}


Here is another example, a little bit more elaborate. Let\textquotesingle{}s assume that you use your own float16 type and you want to use a templated version of the API above so the type is automatically set based on your type. You will need to supply an extra template specialization.


\begin{DoxyCode}{0}
\DoxyCodeLine{namespace\ yours\ \{\ struct\ half\ \{\};\ \}\ //\ assume\ this\ is\ your\ type,\ define\ this:}
\DoxyCodeLine{namespace\ Ort\ \{}
\DoxyCodeLine{template<>}
\DoxyCodeLine{struct\ TypeToTensorType<yours::half>\ \{\ static\ constexpr\ ONNXTensorElementDataType\ type\ =\ ONNX\_TENSOR\_ELEMENT\_DATA\_TYPE\_FLOAT16;\ \};}
\DoxyCodeLine{\}\ //namespace\ Ort}
\DoxyCodeLine{}
\DoxyCodeLine{std::vector<yours::half>\ values;}
\DoxyCodeLine{std::vector<int64\_t>\ dims\ =\ \{values.size()\};\ //\ one\ dimensional\ example}
\DoxyCodeLine{Ort::MemoryInfo\ info("{}Cpu"{},\ OrtDeviceAllocator,\ 0,\ OrtMemTypeDefault);}
\DoxyCodeLine{//\ Here\ we\ are\ passing\ element\ count\ -\/>\ values.size()}
\DoxyCodeLine{auto\ float16\_tensor\ =\ Ort::Value::CreateTensor<yours::half>(info,\ values.data(),\ values.size(),\ dims.data(),\ dims.size());}

\end{DoxyCode}
 

The documentation for this struct was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
C\+:/\+Users/m5963/\+Documents/\+Git\+Hub/\+Anim\+Host/\+Anim\+Host/anim\+Host\+\_\+\+Plugins/\+Basic\+Onnx\+Plugin/onnxruntime/include/onnxruntime\+\_\+cxx\+\_\+api.\+h\end{DoxyCompactItemize}
