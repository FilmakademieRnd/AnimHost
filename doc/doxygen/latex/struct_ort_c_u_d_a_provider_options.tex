\doxysection{Ort\+CUDAProvider\+Options Struct Reference}
\hypertarget{struct_ort_c_u_d_a_provider_options}{}\label{struct_ort_c_u_d_a_provider_options}\index{OrtCUDAProviderOptions@{OrtCUDAProviderOptions}}


CUDA Provider Options.  




{\ttfamily \#include $<$onnxruntime\+\_\+c\+\_\+api.\+h$>$}

\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_ae105c47aba5b45504a830b19a0f9a420}\label{struct_ort_c_u_d_a_provider_options_ae105c47aba5b45504a830b19a0f9a420} 
int {\bfseries device\+\_\+id}
\begin{DoxyCompactList}\small\item\em CUDA device Id Defaults to 0. \end{DoxyCompactList}\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_acc33f79bc3024bfadf2950d139d56370}\label{struct_ort_c_u_d_a_provider_options_acc33f79bc3024bfadf2950d139d56370} 
\mbox{\hyperlink{group___global_ga881a44a5c3499f92d7caa4d7707b5807}{Ort\+Cudnn\+Conv\+Algo\+Search}} {\bfseries cudnn\+\_\+conv\+\_\+algo\+\_\+search}
\begin{DoxyCompactList}\small\item\em CUDA Convolution algorithm search configuration. See enum Ort\+Cudnn\+Conv\+Algo\+Search for more details. Defaults to Ort\+Cudnn\+Conv\+Algo\+Search\+Exhaustive. \end{DoxyCompactList}\item 
size\+\_\+t \mbox{\hyperlink{struct_ort_c_u_d_a_provider_options_a69e9ef15821960254f52adc33a8d0f92}{gpu\+\_\+mem\+\_\+limit}}
\begin{DoxyCompactList}\small\item\em CUDA memory limit (To use all possible memory pass in maximum size\+\_\+t) Defaults to SIZE\+\_\+\+MAX. \end{DoxyCompactList}\item 
int \mbox{\hyperlink{struct_ort_c_u_d_a_provider_options_a6e1465dbb581ba943c92ac595fc4c1d2}{arena\+\_\+extend\+\_\+strategy}}
\begin{DoxyCompactList}\small\item\em Strategy used to grow the memory arena 0 = k\+Next\+Power\+Of\+Two~\newline
 1 = k\+Same\+As\+Requested~\newline
 Defaults to 0. \end{DoxyCompactList}\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_a5186a856edeaf860dc547db309e85f95}\label{struct_ort_c_u_d_a_provider_options_a5186a856edeaf860dc547db309e85f95} 
int {\bfseries do\+\_\+copy\+\_\+in\+\_\+default\+\_\+stream}
\begin{DoxyCompactList}\small\item\em Flag indicating if copying needs to take place on the same stream as the compute stream in the CUDA EP 0 = Use separate streams for copying and compute. 1 = Use the same stream for copying and compute. Defaults to 1. WARNING\+: Setting this to 0 may result in data races for some models. Please see issue \#4829 for more details. \end{DoxyCompactList}\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_a2ca74dbd91996bad4a1c81af705a0ac7}\label{struct_ort_c_u_d_a_provider_options_a2ca74dbd91996bad4a1c81af705a0ac7} 
int {\bfseries has\+\_\+user\+\_\+compute\+\_\+stream}
\begin{DoxyCompactList}\small\item\em Flag indicating if there is a user provided compute stream Defaults to 0. \end{DoxyCompactList}\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_a610a0511f8795bdd2b137f0138cfc88f}\label{struct_ort_c_u_d_a_provider_options_a610a0511f8795bdd2b137f0138cfc88f} 
void \texorpdfstring{$\ast$}{*} {\bfseries user\+\_\+compute\+\_\+stream}
\begin{DoxyCompactList}\small\item\em User provided compute stream. If provided, please set {\ttfamily has\+\_\+user\+\_\+compute\+\_\+stream} to 1. \end{DoxyCompactList}\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_abd39e249214231af0f7d0ebbcd429cef}\label{struct_ort_c_u_d_a_provider_options_abd39e249214231af0f7d0ebbcd429cef} 
Ort\+Arena\+Cfg \texorpdfstring{$\ast$}{*} {\bfseries default\+\_\+memory\+\_\+arena\+\_\+cfg}
\begin{DoxyCompactList}\small\item\em CUDA memory arena configuration parameters. \end{DoxyCompactList}\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_a68c024b598775f289077c6b23aeb3e3e}\label{struct_ort_c_u_d_a_provider_options_a68c024b598775f289077c6b23aeb3e3e} 
int {\bfseries tunable\+\_\+op\+\_\+enable}
\begin{DoxyCompactList}\small\item\em Enable Tunable\+Op for using. Set it to 1/0 to enable/disable Tunable\+Op. Otherwise, it is disabled by default. This option can be overriden by environment variable ORT\+\_\+\+CUDA\+\_\+\+TUNABLE\+\_\+\+OP\+\_\+\+ENABLE. \end{DoxyCompactList}\item 
\Hypertarget{struct_ort_c_u_d_a_provider_options_ac3f1d485877370249c1e3e362fea2d19}\label{struct_ort_c_u_d_a_provider_options_ac3f1d485877370249c1e3e362fea2d19} 
int {\bfseries tunable\+\_\+op\+\_\+tuning\+\_\+enable}
\begin{DoxyCompactList}\small\item\em Enable Tunable\+Op for tuning. Set it to 1/0 to enable/disable Tunable\+Op tuning. Otherwise, it is disabled by default. This option can be overriden by environment variable ORT\+\_\+\+CUDA\+\_\+\+TUNABLE\+\_\+\+OP\+\_\+\+TUNING\+\_\+\+ENABLE. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
CUDA Provider Options. 

\begin{DoxySeeAlso}{See also}
Ort\+Api\+::\+Session\+Options\+Append\+Execution\+Provider\+\_\+\+CUDA 
\end{DoxySeeAlso}


\doxysubsection{Member Data Documentation}
\Hypertarget{struct_ort_c_u_d_a_provider_options_a6e1465dbb581ba943c92ac595fc4c1d2}\label{struct_ort_c_u_d_a_provider_options_a6e1465dbb581ba943c92ac595fc4c1d2} 
\index{OrtCUDAProviderOptions@{OrtCUDAProviderOptions}!arena\_extend\_strategy@{arena\_extend\_strategy}}
\index{arena\_extend\_strategy@{arena\_extend\_strategy}!OrtCUDAProviderOptions@{OrtCUDAProviderOptions}}
\doxysubsubsection{\texorpdfstring{arena\_extend\_strategy}{arena\_extend\_strategy}}
{\footnotesize\ttfamily int Ort\+CUDAProvider\+Options\+::arena\+\_\+extend\+\_\+strategy}



Strategy used to grow the memory arena 0 = k\+Next\+Power\+Of\+Two~\newline
 1 = k\+Same\+As\+Requested~\newline
 Defaults to 0. 

\begin{DoxyNote}{Note}
If a \+::\+Ort\+Arena\+Cfg has been applied, it will override this field 
\end{DoxyNote}
\Hypertarget{struct_ort_c_u_d_a_provider_options_a69e9ef15821960254f52adc33a8d0f92}\label{struct_ort_c_u_d_a_provider_options_a69e9ef15821960254f52adc33a8d0f92} 
\index{OrtCUDAProviderOptions@{OrtCUDAProviderOptions}!gpu\_mem\_limit@{gpu\_mem\_limit}}
\index{gpu\_mem\_limit@{gpu\_mem\_limit}!OrtCUDAProviderOptions@{OrtCUDAProviderOptions}}
\doxysubsubsection{\texorpdfstring{gpu\_mem\_limit}{gpu\_mem\_limit}}
{\footnotesize\ttfamily size\+\_\+t Ort\+CUDAProvider\+Options\+::gpu\+\_\+mem\+\_\+limit}



CUDA memory limit (To use all possible memory pass in maximum size\+\_\+t) Defaults to SIZE\+\_\+\+MAX. 

\begin{DoxyNote}{Note}
If a \+::\+Ort\+Arena\+Cfg has been applied, it will override this field 
\end{DoxyNote}


The documentation for this struct was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
C\+:/\+Users/m5963/\+Documents/\+Git\+Hub/\+Anim\+Host/\+Anim\+Host/anim\+Host\+\_\+\+Plugins/\+Basic\+Onnx\+Plugin/onnxruntime/include/onnxruntime\+\_\+c\+\_\+api.\+h\end{DoxyCompactItemize}
