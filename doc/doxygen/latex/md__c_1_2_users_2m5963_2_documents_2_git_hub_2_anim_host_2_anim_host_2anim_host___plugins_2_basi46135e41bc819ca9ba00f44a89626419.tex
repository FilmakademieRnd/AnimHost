\chapter{README}
\hypertarget{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419}{}\label{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419}\index{README@{README}}




{\bfseries{ONNX Runtime is a cross-\/platform inference and training machine-\/learning accelerator}}.

{\bfseries{ONNX Runtime inference}} can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as Py\+Torch and Tensor\+Flow/\+Keras as well as classical machine learning libraries such as scikit-\/learn, Light\+GBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms. \href{https://www.onnxruntime.ai/docs/\#onnx-runtime-for-inferencing}{\texttt{ Learn more {$\rightarrow$}}}

{\bfseries{ONNX Runtime training}} can accelerate the model training time on multi-\/node NVIDIA GPUs for transformer models with a one-\/line addition for existing Py\+Torch training scripts. \href{https://www.onnxruntime.ai/docs/\#onnx-runtime-for-training}{\texttt{ Learn more {$\rightarrow$}}}\hypertarget{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md5}{}\doxysubsection{\texorpdfstring{Get Started \& Resources}{Get Started \& Resources}}\label{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md5}

\begin{DoxyItemize}
\item {\bfseries{General Information}}\+: \href{https://onnxruntime.ai}{\texttt{ onnxruntime.\+ai}}
\item {\bfseries{Usage documention and tutorials}}\+: \href{https://onnxruntime.ai/docs}{\texttt{ onnxruntime.\+ai/docs}}
\item {\bfseries{You\+Tube video tutorials}}\+: \href{https://www.youtube.com/@ONNXRuntime}{\texttt{ youtube.\+com/@\+ONNXRuntime}}
\item \href{https://github.com/microsoft/onnxruntime/wiki/Upcoming-Release-Roadmap}{\texttt{ {\bfseries{Upcoming Release Roadmap}}}}
\item {\bfseries{Companion sample repositories}}\+:
\begin{DoxyItemize}
\item ONNX Runtime Inferencing\+: \href{https://github.com/microsoft/onnxruntime-inference-examples}{\texttt{ microsoft/onnxruntime-\/inference-\/examples}}
\item ONNX Runtime Training\+: \href{https://github.com/microsoft/onnxruntime-training-examples}{\texttt{ microsoft/onnxruntime-\/training-\/examples}}
\end{DoxyItemize}
\end{DoxyItemize}\hypertarget{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md6}{}\doxysubsection{\texorpdfstring{Build Pipeline Status}{Build Pipeline Status}}\label{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md6}
\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{3}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ System   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Inference   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Training    }\\\cline{1-3}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ System   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Inference   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Training    }\\\cline{1-3}
\endhead
Windows   &\multicolumn{2}{l|}{\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=9}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=10}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=47}{\texttt{ }}    }\\\cline{1-3}
Linux   &\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=11}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=64}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=12}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=45}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=55}{\texttt{ }}   &\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=86}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=84}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=148}{\texttt{ }}    \\\cline{1-3}
Mac   &\multicolumn{2}{l|}{\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=13}{\texttt{ }}    }\\\cline{1-3}
Android   &\multicolumn{2}{l|}{\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=53}{\texttt{ }}    }\\\cline{1-3}
i\+OS   &\multicolumn{2}{l|}{\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=134}{\texttt{ }}    }\\\cline{1-3}
Web   &\multicolumn{2}{l|}{\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=161}{\texttt{ }}    }\\\cline{1-3}
Other   &\multicolumn{2}{l|}{\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=187&repoName=microsoft\%2Fonnxruntime}{\texttt{ }}~\newline
\href{https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=164}{\texttt{ }}   }\\\cline{1-3}
\end{longtabu}
\hypertarget{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md7}{}\doxysubsection{\texorpdfstring{Data/\+Telemetry}{Data/\+Telemetry}}\label{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md7}
Windows distributions of this project may collect usage data and send it to Microsoft to help improve our products and services. See the privacy statement for more details.\hypertarget{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md8}{}\doxysubsection{\texorpdfstring{Contributions and Feedback}{Contributions and Feedback}}\label{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md8}
We welcome contributions! Please see the contribution guidelines.

For feature requests or bug reports, please file a \href{https://github.com/Microsoft/onnxruntime/issues}{\texttt{ Git\+Hub Issue}}.

For general discussion or questions, please use \href{https://github.com/microsoft/onnxruntime/discussions}{\texttt{ Git\+Hub Discussions}}.\hypertarget{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md9}{}\doxysubsection{\texorpdfstring{Code of Conduct}{Code of Conduct}}\label{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md9}
This project has adopted the \href{https://opensource.microsoft.com/codeofconduct/}{\texttt{ Microsoft Open Source Code of Conduct}}. For more information see the \href{https://opensource.microsoft.com/codeofconduct/faq/}{\texttt{ Code of Conduct FAQ}} or contact \href{mailto:opencode@microsoft.com}{\texttt{ opencode@microsoft.\+com}} with any additional questions or comments.\hypertarget{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md10}{}\doxysubsection{\texorpdfstring{License}{License}}\label{md__c_1_2_users_2m5963_2_documents_2_git_hub_2_anim_host_2_anim_host_2anim_host___plugins_2_basi46135e41bc819ca9ba00f44a89626419_autotoc_md10}
This project is licensed under the \mbox{[}MIT License\mbox{]}(LICENSE). 